{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb0a5937-bc38-4158-a068-2cb5c50a0d1a",
   "metadata": {},
   "source": [
    "# Tuning hyperparameters with Optuna\n",
    "\n",
    "All our solvers have got a lot of hyperparameters.\n",
    "And of course, the optimization result can change significantly according to them.\n",
    "\n",
    "In this notebook, we will see how we can make use of [Optuna](https://optuna.readthedocs.io/en/stable/) to tune them for a given problem (or family of problems).\n",
    "\n",
    "Some work has been done in the library to ease this tuning:\n",
    "\n",
    "- main hyperparameters of each solver have been identified, with default values and possible ranges registered;\n",
    "- some utility methods have been coded to get default hyperparameters and to make use of optuna hyperparameters auto-suggestion with as little work as possible from the user.\n",
    "\n",
    "After applying this to tune hyperparameters of a solver, further examples will show you that\n",
    "\n",
    "- we can also use optuna to select the solver class itself as another meta-hyperparameter;\n",
    "- some solvers are meta-solvers having themselves subsolvers as hyperparameters with their own set of hyperparameters, that can also be tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5522765-6e0d-4e06-b0e8-67e78b99bfc7",
   "metadata": {},
   "source": [
    "To illustrate it, we will use the [coloring problem](https://en.wikipedia.org/wiki/Graph_coloring): it consists in coloring vertices of a graph with the minimal number of colors, such that 2 adjacent vertices do not have the same color.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/9/90/Petersen_graph_3-coloring.svg\" alt=\"Petersen graph 3-coloring.svg\"  width=\"280\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96601dbc-2893-4204-b858-d31f99394f55",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Concerning the python kernel to use for this notebook:\n",
    "- If running locally, be sure to use an environment with discrete-optimization, minizinc, and optuna (and optionally optuna-dashboard);\n",
    "- If running on colab, the next cell does it for you;\n",
    "- If running on binder, the environment should be ready.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c42abb-a723-4d23-827a-b4aae1825efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Colab: install the library\n",
    "on_colab = \"google.colab\" in str(get_ipython())\n",
    "if on_colab:\n",
    "    import importlib\n",
    "    import os\n",
    "    import sys  # noqa: avoid having this import removed by pycln\n",
    "\n",
    "    !{sys.executable} -m pip install -U pip\n",
    "\n",
    "    # uninstall google protobuf conflicting with ray and sb3\n",
    "    ! pip uninstall -y protobuf\n",
    "\n",
    "    # install dev version for dev doc, or release version for release doc\n",
    "    !{sys.executable} -m pip install git+https://github.com/airbus/discrete-optimization@master#egg=discrete-optimization\n",
    "\n",
    "    # be sure to load the proper cffi (downgraded compared to the one initially on colab)\n",
    "    import cffi\n",
    "\n",
    "    importlib.reload(cffi)\n",
    "\n",
    "    # install and configure minizinc\n",
    "    !curl -o minizinc.AppImage -L https://github.com/MiniZinc/MiniZincIDE/releases/download/2.6.3/MiniZincIDE-2.6.3-x86_64.AppImage\n",
    "    !chmod +x minizinc.AppImage\n",
    "    !./minizinc.AppImage --appimage-extract\n",
    "    os.environ[\"PATH\"] = f\"{os.getcwd()}/squashfs-root/usr/bin/:{os.environ['PATH']}\"\n",
    "    os.environ[\"LD_LIBRARY_PATH\"] = (\n",
    "        f\"{os.getcwd()}/squashfs-root/usr/lib/:{os.environ['LD_LIBRARY_PATH']}\"\n",
    "    )\n",
    "\n",
    "    # install optuna and optuna-dashboard\n",
    "    !{sys.executable} -m pip install optuna optuna-dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e8c7e5-1334-41b6-b49f-20f97d1df51c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18286ef-28c3-4afc-98a9-85636faa8666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "import socket\n",
    "\n",
    "import nest_asyncio\n",
    "import optuna\n",
    "from optuna.storages import JournalFileStorage, JournalStorage\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "from discrete_optimization.coloring.coloring_parser import (\n",
    "    get_data_available,\n",
    "    parse_file,\n",
    ")\n",
    "from discrete_optimization.coloring.coloring_solvers import look_for_solver\n",
    "from discrete_optimization.coloring.solvers.coloring_cp_lns import LnsCpColoring\n",
    "from discrete_optimization.coloring.solvers.coloring_cpsat_solver import (\n",
    "    ColoringCPSatSolver,\n",
    "    ModelingCPSat,\n",
    ")\n",
    "from discrete_optimization.coloring.solvers.greedy_coloring import (\n",
    "    NXGreedyColoringMethod,\n",
    ")\n",
    "from discrete_optimization.datasets import fetch_data_from_coursera\n",
    "from discrete_optimization.generic_tools.callbacks.loggers import ObjectiveLogger\n",
    "from discrete_optimization.generic_tools.callbacks.optuna import OptunaCallback\n",
    "from discrete_optimization.generic_tools.cp_tools import ParametersCP\n",
    "from discrete_optimization.generic_tools.do_problem import ModeOptim\n",
    "\n",
    "# patch asyncio so that applications using async functions can run in jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# set logging level\n",
    "logging.basicConfig(level=logging.WARNING, format=\"%(asctime)s:%(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb83750-2409-4356-b6cc-5746d4ad0c64",
   "metadata": {},
   "source": [
    "### Download datasets\n",
    "\n",
    "If not yet available, we import the datasets from [coursera](https://github.com/discreteoptimization/assignment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95062a42-bc9b-4abd-aad8-0a60f5e968cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_datasets = [\"gc_70_9\"]\n",
    "download_needed = False\n",
    "try:\n",
    "    files_available_paths = get_data_available()\n",
    "    for dataset in needed_datasets:\n",
    "        if len([f for f in files_available_paths if dataset in f]) == 0:\n",
    "            download_needed = True\n",
    "            break\n",
    "except:\n",
    "    download_needed = True\n",
    "\n",
    "if download_needed:\n",
    "    fetch_data_from_coursera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5802373-8ce1-4677-a0f0-40633d097a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = [f for f in get_data_available() if \"gc_70_9\" in f][0]\n",
    "problem = parse_file(file)\n",
    "print(type(problem))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d250fc6f-958a-4cbf-9d39-0361c546eb15",
   "metadata": {},
   "source": [
    "## Hyperparameters presentation\n",
    "\n",
    "Each solver has some hyperparameters that can be tuned. In this section, we will see how to get the list of them.\n",
    "For recall the hyperparameters are here the keyword arguments to put in a `kwargs` dictionary,\n",
    "that can be used to initialize and run the solver as follows:\n",
    "\n",
    "```python\n",
    "solver = solver_class(problem=problem, **kwargs)\n",
    "solver.init_model(**kwargs)\n",
    "res = solver.solve(**kwargs)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7071bee7-b8a7-465e-a3e8-9dd7f9a26350",
   "metadata": {},
   "source": [
    "Let us take a look to solvers available for the chosen problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbcfdb7-ef2c-4318-9f80-02c122fc8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_classes = look_for_solver(problem)\n",
    "solver_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530c174a-cf97-4000-a03f-9a0dd0f862e1",
   "metadata": {},
   "source": [
    "### Example: ColoringCPSatSolver\n",
    "We can list the hyperparameters available for `ColoringCPSatSolver` with their definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7db3f0-5a2e-4a7d-b0a5-34a17f492624",
   "metadata": {},
   "outputs": [],
   "source": [
    "ColoringCPSatSolver.hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ecd0d-20bc-41b6-a95a-68d42c958d3b",
   "metadata": {},
   "source": [
    "You remark that there are several types of hyperparameters that partially in par with how optuna classify the hyperparameters (integer, float, and categorical):\n",
    "\n",
    "- IntegerHyperparameter: taking integer values within a range;\n",
    "- FloatHyperparameter: taking float values within a range;\n",
    "- CategoricalHyperparameter: taking categorical values within a list of choices, that should be (for optuna) either strings, booleans, integers, or floats;\n",
    "- EnumHyperparameter: extension of categorical hyperparameters, taking value from an enumeration;\n",
    "- SubBrickHyperparameter: extension of categorical hyperparameters, whose values are Hyperparametrizable classes,\n",
    "  generally subsolver classes for meta-solver iterating over a wrapped solver (like [LNS solvers](https://airbus.github.io/discrete-optimization/master/api/discrete_optimization.generic_tools.html#discrete_optimization.generic_tools.lns_cp.LNS_CP)),\n",
    "  but also other bricks like constraint handlers, initial solution provider, or post-processer (also present in LNS solvers);\n",
    "- SubBrickKwargsHyperparameter: correponding to the subset of hyperparameters needed by a hyperparametrizable brick itself defined by a SubBrickHyperparameter.\n",
    "\n",
    "See the [documentation for `discrete_optimization.generic_tools.hyperparameters.hyperparameter` module](https://airbus.github.io/discrete-optimization/master/api/discrete_optimization.generic_tools.hyperparameters.html#module-discrete_optimization.generic_tools.hyperparameters.hyperparameter) for more details.\n",
    "\n",
    "As it can be a bit confusing to have all these details, one can also list only their names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a03ceb-1063-4d8b-9514-3ab2edca3441",
   "metadata": {},
   "outputs": [],
   "source": [
    "ColoringCPSatSolver.get_hyperparameters_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015b3d12-959d-48e9-bf25-83877314aa77",
   "metadata": {},
   "source": [
    "We can create a dictionary with their default values to be used to initialize a solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b4f7c1-421f-4c95-95ac-7163e920e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = ColoringCPSatSolver.get_default_hyperparameters()\n",
    "kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe21b2fd-c19b-4ef4-8de9-674f8a2eb19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = ColoringCPSatSolver(problem=problem, **kwargs)\n",
    "solver.init_model(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32464dff-e733-48eb-8d41-8fd0c8aa0a42",
   "metadata": {},
   "source": [
    "Before solving, we add a timeout parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163b6e8a-49a0-41e5-b74b-8e74c5382076",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_cp = ParametersCP.default()\n",
    "parameters_cp.time_limit = 20\n",
    "res = solver.solve(parameters_cp=parameters_cp, **kwargs)\n",
    "print(f\"Found {len(res.list_solution_fits)} solution(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249f0adb-c849-4d8e-b698-bcb3b956b159",
   "metadata": {},
   "source": [
    "### Meta-solver example: LNS\n",
    "Meta-solvers have sub-brick hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa96ae63-d6b7-4b3e-98d8-50492e99520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LnsCpColoring.get_hyperparameters_by_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14464321-fd63-4fbe-9ede-4fe34db9516c",
   "metadata": {},
   "source": [
    "## Example using Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aedf67-a9cd-4941-920f-667f6906167a",
   "metadata": {},
   "source": [
    "### Without discrete-optimization help\n",
    "\n",
    "To use optuna, we need to define an `objective()` function that returns an objective value to optimize with hyperparameters defined and suggested by optuna on the fly, \n",
    "thanks to methods of the optuna trial passed in argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df52889a-2a22-40f3-bce9-2ccb9bbe8849",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_cp = ParametersCP.default_cpsat()\n",
    "parameters_cp.time_limit = 20\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    # make optuna suggest hyperparameters (and define them doing so)\n",
    "    warmstart = trial.suggest_categorical(name=\"warmstart\", choices=[True, False])\n",
    "    value_sequence_chain = trial.suggest_categorical(\n",
    "        name=\"value_sequence_chain\", choices=[True, False]\n",
    "    )\n",
    "    used_variable = trial.suggest_categorical(\n",
    "        name=\"used_variable\", choices=[True, False]\n",
    "    )\n",
    "    symmetry_on_used = trial.suggest_categorical(\n",
    "        name=\"symmetry_on_used\", choices=[True, False]\n",
    "    )\n",
    "    modeling_str = trial.suggest_categorical(\n",
    "        name=\"modeling\", choices=[m.name for m in ModelingCPSat]\n",
    "    )\n",
    "    greedy_method_str = trial.suggest_categorical(\n",
    "        name=\"greedy_method\", choices=[m.name for m in NXGreedyColoringMethod]\n",
    "    )\n",
    "\n",
    "    # convert optuna values into proper format for d-o\n",
    "    modeling = ModelingCPSat[modeling_str]\n",
    "    greedy_method = NXGreedyColoringMethod[greedy_method_str]\n",
    "\n",
    "    print(f\"Launching trial {trial.number} with parameters: {trial.params}\")\n",
    "\n",
    "    # init solver\n",
    "    kwargs = dict(\n",
    "        warmstart=warmstart,\n",
    "        value_sequence_chain=value_sequence_chain,\n",
    "        used_variable=used_variable,\n",
    "        symmetry_on_used=symmetry_on_used,\n",
    "        modeling=modeling,\n",
    "        greedy_method=greedy_method,\n",
    "    )\n",
    "    solver = ColoringCPSatSolver(problem=problem, **kwargs)\n",
    "    solver.init_model(**kwargs)\n",
    "\n",
    "    # solve\n",
    "    sol, fit = solver.solve(\n",
    "        parameters_cp=parameters_cp, **kwargs\n",
    "    ).get_best_solution_fit()\n",
    "\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5b5851-59cf-4881-9d18-0dc99718508d",
   "metadata": {},
   "source": [
    "Then we create an optuna study and optimize it. Here we choose a limited number of trials for practical reasons but one should allow much more trials to browse the domain of the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960579cd-904d-4d3a-aa85-cc72640df606",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_register = problem.get_objective_register()\n",
    "if objective_register.objective_sense == ModeOptim.MINIMIZATION:\n",
    "    direction = \"minimize\"\n",
    "else:\n",
    "    direction = \"maximize\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=direction,\n",
    ")\n",
    "study.optimize(objective, n_trials=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25a48d1-9c70-4a0f-b752-3decf8cdeed2",
   "metadata": {},
   "source": [
    "Some statistics on the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e78235-31b7-4c47-9cc0-fc05bd1dde26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "print(\"Study statistics: \")\n",
    "print(f\"  Number of finished trials: {len(study.trials)}\")\n",
    "print(f\"  Number of pruned trials: {len(pruned_trials)}\")\n",
    "print(f\"  Number of complete trials: {len(complete_trials)}\")\n",
    "print(\"\")\n",
    "print(\"Best trial:\")\n",
    "print(f\"  value={study.best_trial.value}\")\n",
    "print(f\"  params={study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfc42f3-8c98-4f21-a7d6-e78a65296dd7",
   "metadata": {},
   "source": [
    "We can convert trials into a dataframe to visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c155d-ea26-451f-b072-e75b41145dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = study.trials_dataframe()\n",
    "df.sort_values(\"value\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5331822a-819d-4256-942a-00702d3d3f56",
   "metadata": {},
   "source": [
    "### Taking advantage of discrete-optimization integration of Optuna to choose the hyperparameters\n",
    "\n",
    "Even though the use of optuna is quite easy, typing all hyperparameters can be tedious and prone to errors. \n",
    "And we have seen that some hyperparameters require conversion before being passed to the solver.\n",
    "\n",
    "Discrete-optimization integrate some utility methods that handle it.\n",
    " - Each hyperparameter has a method `suggest_with_optuna()` that calls the appropriate optuna method, potentially with choices/ranges restrictions, and makes the conversion if needed.\n",
    " - Each solver has a method `suggest_hyperparameters_with_optuna()` that suggests directly all (or some) hyperparameters, with the options available for above methods.\n",
    "\n",
    "This lead to the simplified script below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916d18ff-6c58-421c-b6f2-83d7d720de20",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_cp = ParametersCP.default_cpsat()\n",
    "parameters_cp.time_limit = 20\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    # make optuna suggest hyperparameters (and define them doing so)\n",
    "    kwargs = ColoringCPSatSolver.suggest_hyperparameters_with_optuna(trial)\n",
    "\n",
    "    print(f\"Launching trial {trial.number} with parameters: {trial.params}\")\n",
    "\n",
    "    # init solver\n",
    "    solver = ColoringCPSatSolver(problem=problem, **kwargs)\n",
    "    solver.init_model(**kwargs)\n",
    "\n",
    "    # solve\n",
    "    sol, fit = solver.solve(\n",
    "        parameters_cp=parameters_cp, **kwargs\n",
    "    ).get_best_solution_fit()\n",
    "\n",
    "    return fit\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=problem.get_optuna_study_direction(),\n",
    ")\n",
    "study.optimize(objective, n_trials=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df4104a-a82a-456b-bd0e-ff4e9b54c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = study.trials_dataframe()\n",
    "df.sort_values(\"value\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a51b4f-8e19-417d-9339-81b7b358f349",
   "metadata": {},
   "source": [
    "As we did not fixed the seed, the result may vary compared to the previous study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4ce9f4-4309-4332-b060-88bb21e1480e",
   "metadata": {},
   "source": [
    "### Making Optuna prune unpromising trials and visualize intermediate values with optuna-dashboard\n",
    "\n",
    "Optuna is also able to prune unpromising trials if we provide the intermediate objective values at the end of each optimization step.\n",
    "We can achieve this easily by using a dedicated callback during the solve. See the [tutorials on callbacks](./callbacks.ipynb) for more information about how it works.\n",
    "\n",
    "Moreover, we can make use of this reporting to see the study progress \"live\" with optuna-dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67830d4-c0df-45dd-a3e8-b7df19208c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_cp = ParametersCP.default_cpsat()\n",
    "parameters_cp.time_limit = 20\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    # make optuna suggest hyperparameters (and define them doing so)\n",
    "    kwargs = ColoringCPSatSolver.suggest_hyperparameters_with_optuna(trial)\n",
    "\n",
    "    print(f\"Launching trial {trial.number} with parameters: {trial.params}\")\n",
    "\n",
    "    # init solver\n",
    "    solver = ColoringCPSatSolver(problem=problem, **kwargs)\n",
    "    solver.init_model(**kwargs)\n",
    "\n",
    "    # optuna callback\n",
    "    callbacks = [\n",
    "        OptunaCallback(trial=trial),\n",
    "        ObjectiveLogger(\n",
    "            step_verbosity_level=logging.WARNING\n",
    "        ),  # here we set a warning level because `logging` has been set above to display only warning messages.\n",
    "    ]\n",
    "\n",
    "    # solve\n",
    "    sol, fit = solver.solve(\n",
    "        parameters_cp=parameters_cp, callbacks=callbacks, **kwargs\n",
    "    ).get_best_solution_fit()\n",
    "\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8357bd-79b5-4f21-bcc5-1e9faa793b36",
   "metadata": {},
   "source": [
    "To allow visualizing the study (even during the optimization) with optuna-dashboard, we set a storage for the optuna study.\n",
    "We choose a file-based storage but this could be also a database. If you choose a file on NFS, it allows you to launch parallel optuna instances to speed up the tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35e9934-1424-4e9b-8c26-23e701e2c977",
   "metadata": {},
   "source": [
    "If the study is already existing (because you already run this notebook for instance), you can either:\n",
    "- set the option `load_if_exists=True`, and the study will add the new trials to the already existing study (and thus use the knowledge of previous trials)\n",
    "- change the name of the study to keep the previous results but not reuse them\n",
    "- delete the study to overwrite it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d0657-0776-499a-8cf1-18d0380e6e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_journal_filepath = \"optuna-journal.log\"\n",
    "study_name = \"optuna-coloring-with-pruning\"\n",
    "overwrite = False\n",
    "\n",
    "storage = JournalStorage(JournalFileStorage(optuna_journal_filepath))\n",
    "if overwrite:\n",
    "    try:\n",
    "        optuna.delete_study(study_name=study_name, storage=storage)\n",
    "    except:\n",
    "        pass\n",
    "    load_if_exists = False\n",
    "else:\n",
    "    load_if_exists = True\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    direction=problem.get_optuna_study_direction(),\n",
    "    storage=storage,\n",
    "    load_if_exists=load_if_exists,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b226dce9-4408-40f7-a3de-8e8a368e1221",
   "metadata": {},
   "source": [
    "While the study runs, we can watch the optimization progress thanks to optuna-dashboard with\n",
    "\n",
    "    optuna-dashboard optuna-journal.log\n",
    "\n",
    "The next cell do it according to your jupyter environment:\n",
    "- if running locally, we need to install optuna-dashboard and run it (in a separate process);\n",
    "- if running on colab, we make use of `google.colab.output` as suggested [here](https://stackoverflow.com/a/76033378);\n",
    "- if running on binder, we sadly did not succed in using `jupyter-server-proxy` to access to the served dashboard, as done for tensorboard [here](https://github.com/binder-examples/tensorboard).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc8e52-c216-4f9c-86b6-9b019ec77877",
   "metadata": {},
   "outputs": [],
   "source": [
    "on_colab = \"google.colab\" in str(get_ipython())  # running on colab?\n",
    "on_binder = socket.gethostname().startswith(\n",
    "    \"jupyter-\"\n",
    ")  # running on binder? (not 100% sure but rather robust)\n",
    "\n",
    "\n",
    "def start_optuna_dashboard(port=1234):\n",
    "    import threading\n",
    "    import time\n",
    "    from wsgiref.simple_server import make_server\n",
    "\n",
    "    from optuna_dashboard import wsgi\n",
    "\n",
    "    app = wsgi(storage)\n",
    "    httpd = make_server(\"localhost\", port, app)\n",
    "    thread = threading.Thread(target=httpd.serve_forever)\n",
    "    thread.start()\n",
    "    time.sleep(3)  # Wait until the server startup\n",
    "    return port\n",
    "\n",
    "\n",
    "if on_colab:\n",
    "    port = start_optuna_dashboard()\n",
    "    from google.colab import output\n",
    "\n",
    "    print(\"Visit optuna-dashboard on:\")\n",
    "    output.serve_kernel_port_as_window(port, path=\"/dashboard/\")\n",
    "\n",
    "elif on_binder:\n",
    "    print(\"Not yet working on binder...\")\n",
    "else:\n",
    "    try:\n",
    "        import optuna_dashboard  # nopycln: import\n",
    "    except ImportError:\n",
    "        !pip install optuna-dashboard\n",
    "    port = start_optuna_dashboard()\n",
    "    print(f\"Visit optuna-dashboard on http://localhost:{port}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4578874-7455-4b97-b3cf-a3c759b68080",
   "metadata": {},
   "source": [
    "We set a greater number of trials to see pruning in action. (By default, optuna is using a [MedianPruner](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.MedianPruner.html).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a55e833-54d1-4572-8018-7dbc7647593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0360be25-8740-4273-8e4f-0efc56c2140e",
   "metadata": {},
   "source": [
    "## Full example selecting solver classes with their hyperparameters\n",
    "\n",
    "If we see the main solver class as a categorical hyperparameter itself (like in meta-solver example), we can let Optuna also choose it.\n",
    "\n",
    "A full example can be found as a script in the repository that\n",
    "- chooses the solving method\n",
    "- chooses the related hyperparameters\n",
    "- specifies some fixed parameters like timeout limits\n",
    "- freezes some hyperparameters\n",
    "- restrict the choices for some hyperparameters\n",
    "- stores optuna results in a file\n",
    "  - potentially distributed on NFS for parallel tuning\n",
    "  - allowing real-time visualization with optuna-dashboard\n",
    "- prunes unpromising trials according to the computation time (instead of steps)\n",
    "  as we compare different solvers between them that have different notions of optimization step\n",
    "\n",
    "\n",
    "This is \"examples/coloring/optuna_full_example_all_solvers_timed_pruning.py\" ([local link](../../examples/coloring/optuna_full_example_all_solvers_timed_pruning.py), [github link](https://github.com/airbus/discrete-optimization/tree/master/examples/coloring/optuna_full_example_all_solvers_timed_pruning.py))."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
